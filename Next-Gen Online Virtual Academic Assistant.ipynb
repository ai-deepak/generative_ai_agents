{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae6db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import operator\n",
    "from functools import reduce\n",
    "from typing import Annotated, List, Dict, TypedDict, Literal, Optional, Callable, Set, Tuple, Any, Union, TypeVar\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from operator import add\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, Graph, END, START\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text\n",
    "from rich import box\n",
    "from rich.style import Style\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c344d5-7320-4dcf-8b92-fbab4d76a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMOTRON_4_340B_INSTRUCT_KEY = os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2df006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key configured: True\n"
     ]
    }
   ],
   "source": [
    "def configure_api_keys():\n",
    "    \"\"\"Configure and verify API keys for LLM services.\"\"\"\n",
    "\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\")\n",
    "\n",
    "    is_configured = bool(os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\"))\n",
    "    print(f\"API Key configured: {is_configured}\")\n",
    "    return is_configured\n",
    "\n",
    "api_configured = configure_api_keys()\n",
    "if not api_configured:\n",
    "    print(\"\\nAPI key not found. Please ensure you have:\")\n",
    "    print(\"1. Created a .env file with NEMOTRON_4_340B_INSTRUCT_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d636c0-8c77-4f1e-839f-1254b53ef9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "def dict_reducer(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Merge two dictionaries recursively\n",
    "\n",
    "    Example:\n",
    "    dict1 = {\"a\": {\"x\": 1}, \"b\": 2}\n",
    "    dict2 = {\"a\": {\"y\": 2}, \"c\": 3}\n",
    "    result = {\"a\": {\"x\": 1, \"y\": 2}, \"b\": 2, \"c\": 3}\n",
    "    \"\"\"\n",
    "    merged = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n",
    "            merged[key] = dict_reducer(merged[key], value)\n",
    "        else:\n",
    "            merged[key] = value\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65c565a-0419-466c-9fb9-9a4ee03a180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcademicState(TypedDict):\n",
    "    \"\"\"Master state container for the academic assistance system\"\"\"\n",
    "    #  messages: Annotated[List[BaseMessage], add]   # Conversation history\n",
    "    #  profile: dict                                 # Student information\n",
    "    #  calendar: dict                                # Scheduled events\n",
    "    #  tasks: dict                                   # To-do items and assignments\n",
    "    #  results: Dict[str, Any]                       # Operation outputs\n",
    "    messages: Annotated[List[BaseMessage], add]   # Conversation history\n",
    "    profile: Annotated[Dict, dict_reducer]                 # Student information\n",
    "    calendar: Annotated[Dict, dict_reducer]                # Scheduled events\n",
    "    tasks: Annotated[Dict, dict_reducer]                   # To-do items and assignments\n",
    "    results: Annotated[Dict[str, Any], dict_reducer]       # Operation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e74883-be5c-4fd9-81ff-a2224cc04339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMConfig:\n",
    "    \"\"\"Configuration settings for the LLM.\"\"\"\n",
    "    base_url: str = \"https://integrate.api.nvidia.com/v1\"\n",
    "    model: str = \"nvidia/nemotron-4-340b-instruct\"\n",
    "    max_tokens: int = 1024\n",
    "    default_temp: float = 0.5\n",
    "\n",
    "class NeMoLLaMa:\n",
    "  \"\"\"\n",
    "  A class to interact with NVIDIA's nemotron-4-340b-instruct model through their API\n",
    "  This implementation uses AsyncOpenAI client for asynchronous operations\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, api_key: str):\n",
    "    \"\"\"Initialize NeMoLLaMa with API key.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): NVIDIA API authentication key\n",
    "    \"\"\"\n",
    "    self.config = LLMConfig()\n",
    "    self.client = AsyncOpenAI(\n",
    "        base_url=self.config.base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    self._is_authenticated = False\n",
    "\n",
    "  async def check_auth(self) -> bool:\n",
    "      \"\"\"Verify API authentication with test request.\n",
    "\n",
    "      Returns:\n",
    "          bool: Authentication status\n",
    "\n",
    "      Example:\n",
    "          >>> is_valid = await llm.check_auth()\n",
    "          >>> print(f\"Authenticated: {is_valid}\")\n",
    "      \"\"\"\n",
    "      test_message = [{\"role\": \"user\", \"content\": \"test\"}]\n",
    "      try:\n",
    "          await self.agenerate(test_message, temperature=0.1)\n",
    "          self._is_authenticated = True\n",
    "          return True\n",
    "      except Exception as e:\n",
    "          print(f\"❌ Authentication failed: {str(e)}\")\n",
    "          return False\n",
    "\n",
    "  async def agenerate(\n",
    "      self,\n",
    "      messages: List[Dict],\n",
    "      temperature: Optional[float] = None\n",
    "  ) -> str:\n",
    "      \"\"\"Generate text using NeMo LLaMa model.\n",
    "\n",
    "      Args:\n",
    "          messages: List of message dicts with 'role' and 'content'\n",
    "          temperature: Sampling temperature (0.0 to 1.0, default from config)\n",
    "\n",
    "      Returns:\n",
    "          str: Generated text response\n",
    "\n",
    "      Example:\n",
    "          >>> messages = [\n",
    "          ...     {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "          ...     {\"role\": \"user\", \"content\": \"Plan my study schedule\"}\n",
    "          ... ]\n",
    "          >>> response = await llm.agenerate(messages, temperature=0.7)\n",
    "      \"\"\"\n",
    "      completion = await self.client.chat.completions.create(\n",
    "          model=self.config.model,\n",
    "          messages=messages,\n",
    "          temperature=temperature or self.config.default_temp,\n",
    "          max_tokens=self.config.max_tokens,\n",
    "          stream=False\n",
    "      )\n",
    "      return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e3e3d8-5153-409c-a227-021ed8bce237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize data storage containers.\n",
    "        All data sources start as None until explicitly loaded through load_data().\n",
    "        \"\"\"\n",
    "        self.profile_data = None\n",
    "        self.calendar_data = None\n",
    "        self.task_data = None\n",
    "\n",
    "    def load_data(self, profile_json: str, calendar_json: str, task_json: str):\n",
    "        \"\"\"\n",
    "        Load and parse multiple JSON data sources simultaneously.\n",
    "\n",
    "        Args:\n",
    "            profile_json (str): JSON string containing user profile information\n",
    "            calendar_json (str): JSON string containing calendar events\n",
    "            task_json (str): JSON string containing task/todo items\n",
    "\n",
    "        Note: This method expects valid JSON strings. Any parsing errors will propagate up.\n",
    "        \"\"\"\n",
    "        self.profile_data = profile_json\n",
    "        self.calendar_data = calendar_json\n",
    "        self.task_data = task_json\n",
    "\n",
    "    def get_student_profile(self, student_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve a specific student's profile using their unique identifier.\n",
    "\n",
    "        Args:\n",
    "            student_id (str): Unique identifier for the student\n",
    "\n",
    "        Returns:\n",
    "            Dict: Student profile data if found, None otherwise\n",
    "\n",
    "        Implementation Note:\n",
    "            Uses generator expression with next() for efficient search through profiles,\n",
    "            avoiding full list iteration when possible.\n",
    "        \"\"\"\n",
    "        if self.profile_data:\n",
    "            return next((p for p in self.profile_data[\"profiles\"] if p[\"student_id\"] == student_id), None)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def parse_datetime(self, dt_str: str) -> datetime:\n",
    "        \"\"\"\n",
    "        Smart datetime parser that handles multiple formats and ensures UTC timezone.\n",
    "\n",
    "        Args:\n",
    "            dt_str (str): DateTime string in ISO format, with or without timezone\n",
    "\n",
    "        Returns:\n",
    "            datetime: Parsed datetime object in UTC timezone\n",
    "\n",
    "        Implementation Note:\n",
    "            Handles both timezone-aware and naive datetime strings by:\n",
    "            1. First attempting to parse with timezone information\n",
    "            2. Falling back to assuming UTC if no timezone is specified\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # First attempt: Parse ISO format with timezone\n",
    "            dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))\n",
    "            return dt.astimezone(timezone.utc)\n",
    "        except ValueError:\n",
    "            # Fallback: Assume UTC if no timezone provided\n",
    "            dt = datetime.fromisoformat(dt_str)\n",
    "            return dt.replace(tzinfo=timezone.utc)\n",
    "\n",
    "    def get_upcoming_events(self, days: int = 7) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Intelligently filter and retrieve upcoming calendar events within a specified timeframe.\n",
    "\n",
    "        Args:\n",
    "            days (int): Number of days to look ahead (default: 7)\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of upcoming events, chronologically ordered\n",
    "\n",
    "        Implementation Note:\n",
    "            - Uses UTC timestamps for consistent timezone handling\n",
    "            - Implements error handling for malformed event data\n",
    "            - Only includes events that start in the future up to the specified timeframe\n",
    "        \"\"\"\n",
    "        if not self.calendar_data:\n",
    "            return []\n",
    "\n",
    "        now = datetime.now(timezone.utc)\n",
    "        future = now + timedelta(days=days)\n",
    "\n",
    "        events = []\n",
    "        for event in self.calendar_data.get(\"events\", []):\n",
    "            try:\n",
    "                start_time = self.parse_datetime(event[\"start\"][\"dateTime\"])\n",
    "\n",
    "                if now <= start_time <= future:\n",
    "                    events.append(event)\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Warning: Could not process event due to {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return events\n",
    "\n",
    "    def get_active_tasks(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve and filter active tasks, enriching them with parsed datetime information.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of active tasks with parsed due dates\n",
    "\n",
    "        Implementation Note:\n",
    "            - Filters for tasks that are:\n",
    "              1. Not completed (\"needsAction\" status)\n",
    "              2. Due in the future\n",
    "            - Enriches task objects with parsed datetime for easier processing\n",
    "            - Implements robust error handling for malformed task data\n",
    "        \"\"\"\n",
    "        if not self.task_data:\n",
    "            return []\n",
    "\n",
    "        now = datetime.now(timezone.utc)\n",
    "        active_tasks = []\n",
    "\n",
    "        for task in self.task_data.get(\"tasks\", []):\n",
    "            try:\n",
    "                due_date = self.parse_datetime(task[\"due\"])\n",
    "                if task[\"status\"] == \"needsAction\" and due_date > now:\n",
    "                    # Enrich task object with parsed datetime\n",
    "                    task[\"due_datetime\"] = due_date\n",
    "                    active_tasks.append(task)\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Warning: Could not process task due to {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return active_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd51238-b922-4e3b-abbc-2be7d7badec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.NeMoLLaMa object at 0x000002E1233AC210>\n"
     ]
    }
   ],
   "source": [
    "llm = NeMoLLaMa(NEMOTRON_4_340B_INSTRUCT_KEY)\n",
    "data_manager = DataManager()\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acf8811-a654-488f-99c8-09ed632c991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentExecutor:\n",
    "\n",
    "\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the executor with a language model and create agent instances.\n",
    "\n",
    "        Args:\n",
    "            llm: Language model instance to be used by all agents\n",
    "\n",
    "        Implementation Note:\n",
    "            - Creates a dictionary of specialized agents, each initialized with the same LLM\n",
    "            - Supports multiple agent types: PLANNER (default), NOTEWRITER, and ADVISOR\n",
    "            - Agents are instantiated once and reused across executions\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.agents = {\n",
    "            \"PLANNER\": PlannerAgent(llm),      # Strategic planning agent\n",
    "            \"NOTEWRITER\": NoteWriterAgent(llm), # Documentation agent\n",
    "            \"ADVISOR\": AdvisorAgent(llm)        # Academic advice agent\n",
    "        }\n",
    "\n",
    "    async def execute(self, state: AcademicState) -> Dict:\n",
    "        \"\"\"\n",
    "        Orchestrates concurrent execution of multiple AI agents based on analysis results.\n",
    "\n",
    "        This method implements a sophisticated execution pattern:\n",
    "        1. Reads coordination analysis to determine required agents\n",
    "        2. Groups agents for concurrent execution\n",
    "        3. Executes agent groups in parallel\n",
    "        4. Handles failures gracefully with fallback mechanisms\n",
    "\n",
    "        Args:\n",
    "            state (AcademicState): Current academic state containing analysis results\n",
    "\n",
    "        Returns:\n",
    "            Dict: Consolidated results from all executed agents\n",
    "\n",
    "        Implementation Details:\n",
    "        ---------------------\n",
    "        1. Analysis Interpretation:\n",
    "           - Extracts coordination analysis from state\n",
    "           - Determines required agents and their concurrent execution groups\n",
    "\n",
    "        2. Concurrent Execution Pattern:\n",
    "           - Processes agents in groups that can run in parallel\n",
    "           - Uses asyncio.gather() for concurrent execution within each group\n",
    "           - Only executes agents that are both required and available\n",
    "\n",
    "        3. Result Management:\n",
    "           - Collects and processes results from each concurrent group\n",
    "           - Filters out failed executions (exceptions)\n",
    "           - Formats successful results into a structured output\n",
    "\n",
    "        4. Fallback Mechanisms:\n",
    "           - If no results are gathered, falls back to PLANNER agent\n",
    "           - Provides emergency fallback plan in case of complete failure\n",
    "\n",
    "        Error Handling:\n",
    "        --------------\n",
    "        - Catches and handles exceptions at multiple levels:\n",
    "          * Individual agent execution failures don't affect other agents\n",
    "          * System-level failures trigger emergency fallback\n",
    "        - Maintains system stability through graceful degradation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract coordination analysis from state\n",
    "            analysis = state[\"results\"].get(\"coordinator_analysis\", {})\n",
    "\n",
    "            # Determine execution requirements\n",
    "            required_agents = analysis.get(\"required_agents\", [\"PLANNER\"])  # PLANNER as default\n",
    "            concurrent_groups = analysis.get(\"concurrent_groups\", [])       # Groups for parallel execution\n",
    "\n",
    "            # Initialize results container\n",
    "            results = {}\n",
    "\n",
    "            # Process each concurrent group sequentially\n",
    "            for group in concurrent_groups:\n",
    "                # Prepare concurrent tasks for current group\n",
    "                tasks = []\n",
    "                for agent_name in group:\n",
    "                    # Validate agent availability and requirement\n",
    "                    if agent_name in required_agents and agent_name in self.agents:\n",
    "                        tasks.append(self.agents[agent_name](state))\n",
    "\n",
    "                # Execute group tasks concurrently if any exist\n",
    "                if tasks:\n",
    "                    # Gather results from concurrent execution\n",
    "                    group_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "                    # Process successful results only\n",
    "                    for agent_name, result in zip(group, group_results):\n",
    "                        if not isinstance(result, Exception):\n",
    "                            results[agent_name.lower()] = result\n",
    "\n",
    "            # Implement fallback strategy if no results were obtained\n",
    "            if not results and \"PLANNER\" in self.agents:\n",
    "                planner_result = await self.agents[\"PLANNER\"](state)\n",
    "                results[\"planner\"] = planner_result\n",
    "\n",
    "            print(\"agent_outputs\", results)\n",
    "\n",
    "            # Return structured results\n",
    "            return {\n",
    "                \"results\": {\n",
    "                    \"agent_outputs\": results\n",
    "                }\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Execution error: {e}\")\n",
    "            # Emergency fallback with minimal response\n",
    "            return {\n",
    "                \"results\": {\n",
    "                    \"agent_outputs\": {\n",
    "                        \"planner\": {\n",
    "                            \"plan\": \"Emergency fallback plan: Please try again or contact support.\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eac0588-31eb-4e4c-8b2c-03ba016240b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentAction(BaseModel):\n",
    "   \"\"\"\n",
    "   Model representing an agent's action decision.\n",
    "\n",
    "   Attributes:\n",
    "       action (str): The specific action to be taken (e.g., \"search_calendar\", \"analyze_tasks\")\n",
    "       thought (str): The reasoning process behind the action choice\n",
    "       tool (Optional[str]): The specific tool to be used for the action (if needed)\n",
    "       action_input (Optional[Dict]): Input parameters for the action\n",
    "\n",
    "   Example:\n",
    "       >>> action = AgentAction(\n",
    "       ...     action=\"search_calendar\",\n",
    "       ...     thought=\"Need to check schedule conflicts\",\n",
    "       ...     tool=\"calendar_search\",\n",
    "       ...     action_input={\"date_range\": \"next_week\"}\n",
    "       ... )\n",
    "   \"\"\"\n",
    "   action: str      # Required action to be performed\n",
    "   thought: str     # Reasoning behind the action\n",
    "   tool: Optional[str] = None        # Optional tool specification\n",
    "   action_input: Optional[Dict] = None  # Optional input parameters\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "   \"\"\"\n",
    "   Model representing the output from an agent's action.\n",
    "\n",
    "   Attributes:\n",
    "       observation (str): The result or observation from executing the action\n",
    "       output (Dict): Structured output data from the action\n",
    "\n",
    "   Example:\n",
    "       >>> output = AgentOutput(\n",
    "       ...     observation=\"Found 3 free time slots next week\",\n",
    "       ...     output={\n",
    "       ...         \"free_slots\": [\"Mon 2PM\", \"Wed 10AM\", \"Fri 3PM\"],\n",
    "       ...         \"conflicts\": []\n",
    "       ...     }\n",
    "       ... )\n",
    "   \"\"\"\n",
    "   observation: str  # Result or observation from the action\n",
    "   output: Dict     # Structured output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cade3e28-da4c-4495-a9f3-543a99f11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "  \"\"\"\n",
    "    Base class for ReACT-based agents implementing reasoning and action capabilities.\n",
    "\n",
    "    Features:\n",
    "    - Tool management for specific actions\n",
    "    - Few-shot learning examples\n",
    "    - Structured thought process\n",
    "    - Action execution framework\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, llm):\n",
    "      \"\"\"\n",
    "      Initialize the ReActAgent with language model and available tools\n",
    "\n",
    "      Args:\n",
    "          llm: Language model instance for agent operations\n",
    "      \"\"\"\n",
    "      self.llm = llm\n",
    "      # Storage for few-shot examples to guide the agent\n",
    "      self.few_shot_examples = []\n",
    "\n",
    "      # Dictionary of available tools with their corresponding methods\n",
    "      self.tools = {\n",
    "          \"search_calendar\": self.search_calendar,      # Calendar search functionality\n",
    "          \"analyze_tasks\": self.analyze_tasks,          # Task analysis functionality\n",
    "          \"check_learning_style\": self.check_learning_style,  # Learning style assessment\n",
    "          \"check_performance\": self.check_performance   # Academic performance checking\n",
    "      }\n",
    "\n",
    "  async def search_calendar(self, state: AcademicState) -> List[Dict]:\n",
    "      \"\"\"\n",
    "      Search for upcoming calendar events\n",
    "\n",
    "      Args:\n",
    "          state (AcademicState): Current academic state\n",
    "\n",
    "      Returns:\n",
    "          List[Dict]: List of upcoming calendar events\n",
    "      \"\"\"\n",
    "      # Get events from calendar or empty list if none exist\n",
    "      events = state[\"calendar\"].get(\"events\", [])\n",
    "      # Get current time in UTC\n",
    "      now = datetime.now(timezone.utc)\n",
    "      # Filter and return only future events\n",
    "      return [e for e in events if datetime.fromisoformat(e[\"start\"][\"dateTime\"]) > now]\n",
    "\n",
    "  async def analyze_tasks(self, state: AcademicState) -> List[Dict]:\n",
    "      \"\"\"\n",
    "      Analyze academic tasks from the current state\n",
    "\n",
    "      Args:\n",
    "          state (AcademicState): Current academic state\n",
    "\n",
    "      Returns:\n",
    "          List[Dict]: List of academic tasks\n",
    "      \"\"\"\n",
    "      # Return tasks or empty list if none exist\n",
    "      return state[\"tasks\"].get(\"tasks\", [])\n",
    "\n",
    "  async def check_learning_style(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"\n",
    "        Retrieve student's learning style and study patterns\n",
    "\n",
    "        Args:\n",
    "            state (AcademicState): Current academic state\n",
    "\n",
    "        Returns:\n",
    "            AcademicState: Updated state with learning style analysis\n",
    "        \"\"\"\n",
    "        # Get user profile from state\n",
    "        profile = state[\"profile\"]\n",
    "\n",
    "        # Get learning preferences\n",
    "        learning_data = {\n",
    "            \"style\": profile.get(\"learning_preferences\", {}).get(\"learning_style\", {}),\n",
    "            \"patterns\": profile.get(\"learning_preferences\", {}).get(\"study_patterns\", {})\n",
    "        }\n",
    "\n",
    "        # Add to results in state\n",
    "        if \"results\" not in state:\n",
    "            state[\"results\"] = {}\n",
    "        state[\"results\"][\"learning_analysis\"] = learning_data\n",
    "\n",
    "        return state\n",
    "\n",
    "  async def check_performance(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"\n",
    "        Check current academic performance across courses\n",
    "\n",
    "        Args:\n",
    "            state (AcademicState): Current academic state\n",
    "\n",
    "        Returns:\n",
    "            AcademicState: Updated state with performance analysis\n",
    "        \"\"\"\n",
    "        # Get user profile from state\n",
    "        profile = state[\"profile\"]\n",
    "\n",
    "        # Get course information\n",
    "        courses = profile.get(\"academic_info\", {}).get(\"current_courses\", [])\n",
    "\n",
    "        # Add to results in state\n",
    "        if \"results\" not in state:\n",
    "            state[\"results\"] = {}\n",
    "        state[\"results\"][\"performance_analysis\"] = {\"courses\": courses}\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6c11c7-7768-4f25-8d52-bbb6aa499c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_context(state: AcademicState) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyzes the academic state context to inform coordinator decision-making.\n",
    "\n",
    "    This function performs comprehensive context analysis by:\n",
    "    1. Extracting student profile information\n",
    "    2. Analyzing calendar and task loads\n",
    "    3. Identifying relevant course context from the latest message\n",
    "    4. Gathering learning preferences and study patterns\n",
    "\n",
    "    Args:\n",
    "        state (AcademicState): Current academic state including profile, calendar, and tasks\n",
    "\n",
    "    Returns:\n",
    "        Dict: Structured analysis of the student's context for decision making\n",
    "\n",
    "    Implementation Notes:\n",
    "    ------------------\n",
    "    - Extracts information hierarchically using nested get() operations for safety\n",
    "    - Identifies current course context from the latest message content\n",
    "    - Provides default values for missing information to ensure stability\n",
    "    \"\"\"\n",
    "    # Extract main data components with safe navigation\n",
    "    profile = state.get(\"profile\", {})\n",
    "    calendar = state.get(\"calendar\", {})\n",
    "    tasks = state.get(\"tasks\", {})\n",
    "\n",
    "    # Extract course information and match with current request\n",
    "    courses = profile.get(\"academic_info\", {}).get(\"current_courses\", [])\n",
    "    current_course = None\n",
    "    request = state[\"messages\"][-1].content.lower()  # Latest message for context\n",
    "\n",
    "    # Identify relevant course from request content\n",
    "    for course in courses:\n",
    "        if course[\"name\"].lower() in request:\n",
    "            current_course = course\n",
    "            break\n",
    "\n",
    "    # Construct comprehensive context analysis\n",
    "    return {\n",
    "        \"student\": {\n",
    "            \"major\": profile.get(\"personal_info\", {}).get(\"major\", \"Unknown\"),\n",
    "            \"year\": profile.get(\"personal_info\", {}).get(\"academic_year\"),\n",
    "            \"learning_style\": profile.get(\"learning_preferences\", {}).get(\"learning_style\", {}),\n",
    "        },\n",
    "        \"course\": current_course,\n",
    "        \"upcoming_events\": len(calendar.get(\"events\", [])),  # Calendar load indicator\n",
    "        \"active_tasks\": len(tasks.get(\"tasks\", [])),        # Task load indicator\n",
    "        \"study_patterns\": profile.get(\"learning_preferences\", {}).get(\"study_patterns\", {})\n",
    "    }\n",
    "\n",
    "def parse_coordinator_response(response: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parses LLM coordinator response into structured analysis for agent execution.\n",
    "\n",
    "    This function implements a robust parsing strategy:\n",
    "    1. Starts with safe default configuration\n",
    "    2. Analyzes ReACT patterns in the response\n",
    "    3. Adjusts agent requirements and priorities based on content\n",
    "    4. Organizes concurrent execution groups\n",
    "\n",
    "    Args:\n",
    "        response (str): Raw LLM response text\n",
    "\n",
    "    Returns:\n",
    "        Dict: Structured analysis containing:\n",
    "            - required_agents: List of agents needed\n",
    "            - priority: Priority levels for each agent\n",
    "            - concurrent_groups: Groups of agents that can run together\n",
    "            - reasoning: Extracted reasoning for decisions\n",
    "\n",
    "    Implementation Notes:\n",
    "    ------------------\n",
    "    1. Default Configuration:\n",
    "       - Always includes PLANNER agent as baseline\n",
    "       - Sets basic priority and concurrent execution structure\n",
    "\n",
    "    2. Response Analysis:\n",
    "       - Looks for ReACT patterns (Thought/Decision structure)\n",
    "       - Identifies agent requirements from content keywords\n",
    "       - Extracts reasoning from thought section\n",
    "\n",
    "    3. Agent Configuration:\n",
    "       - NOTEWRITER triggered by note-taking related content\n",
    "       - ADVISOR triggered by guidance/advice related content\n",
    "       - Organizes concurrent execution groups based on dependencies\n",
    "\n",
    "    4. Error Handling:\n",
    "       - Provides fallback configuration if parsing fails\n",
    "       - Maintains system stability through default values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize with safe default configuration\n",
    "        analysis = {\n",
    "            \"required_agents\": [\"PLANNER\"],         # PLANNER is always required\n",
    "            \"priority\": {\"PLANNER\": 1},             # Base priority structure\n",
    "            \"concurrent_groups\": [[\"PLANNER\"]],     # Default execution group\n",
    "            \"reasoning\": \"Default coordination\"      # Default reasoning\n",
    "        }\n",
    "\n",
    "        # Parse ReACT patterns for advanced coordination\n",
    "        if \"Thought:\" in response and \"Decision:\" in response:\n",
    "            # Check for NOTEWRITER requirements\n",
    "            if \"NoteWriter\" in response or \"note\" in response.lower():\n",
    "                analysis[\"required_agents\"].append(\"NOTEWRITER\")\n",
    "                analysis[\"priority\"][\"NOTEWRITER\"] = 2\n",
    "                # NOTEWRITER can run concurrently with PLANNER\n",
    "                analysis[\"concurrent_groups\"] = [[\"PLANNER\", \"NOTEWRITER\"]]\n",
    "\n",
    "            # Check for ADVISOR requirements\n",
    "            if \"Advisor\" in response or \"guidance\" in response.lower():\n",
    "                analysis[\"required_agents\"].append(\"ADVISOR\")\n",
    "                analysis[\"priority\"][\"ADVISOR\"] = 3\n",
    "                # ADVISOR typically runs after initial planning\n",
    "\n",
    "            # Extract and store reasoning from thought section\n",
    "            thought_section = response.split(\"Thought:\")[1].split(\"Action:\")[0].strip()\n",
    "            analysis[\"reasoning\"] = thought_section\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {str(e)}\")\n",
    "        # Fallback to safe default configuration\n",
    "        return {\n",
    "            \"required_agents\": [\"PLANNER\"],\n",
    "            \"priority\": {\"PLANNER\": 1},\n",
    "            \"concurrent_groups\": [[\"PLANNER\"]],\n",
    "            \"reasoning\": \"Fallback due to parse error\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68b5607-d9d9-4029-9fb0-b9fc25795d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDINATOR_PROMPT =\"\"\"You are a Coordinator Agent using ReACT framework to orchestrate multiple academic support agents.\n",
    "\n",
    "        AVAILABLE AGENTS:\n",
    "        • PLANNER: Handles scheduling and time management\n",
    "        • NOTEWRITER: Creates study materials and content summaries\n",
    "        • ADVISOR: Provides personalized academic guidance\n",
    "\n",
    "        PARALLEL EXECUTION RULES:\n",
    "        1. Group compatible agents that can run concurrently\n",
    "        2. Maintain dependencies between agent executions\n",
    "        3. Coordinate results from parallel executions\n",
    "\n",
    "        REACT PATTERN:\n",
    "        Thought: [Analyze request complexity and required support types]\n",
    "        Action: [Select optimal agent combination]\n",
    "        Observation: [Evaluate selected agents' capabilities]\n",
    "        Decision: [Finalize agent deployment plan]\n",
    "\n",
    "        ANALYSIS POINTS:\n",
    "        1. Task Complexity and Scope\n",
    "        2. Time Constraints\n",
    "        3. Resource Requirements\n",
    "        4. Learning Style Alignment\n",
    "        5. Support Type Needed\n",
    "\n",
    "        CONTEXT:\n",
    "        Request: {request}\n",
    "        Student Context: {context}\n",
    "\n",
    "        FORMAT RESPONSE AS:\n",
    "        Thought: [Analysis of academic needs and context]\n",
    "        Action: [Agent selection and grouping strategy]\n",
    "        Observation: [Expected workflow and dependencies]\n",
    "        Decision: [Final agent deployment plan with rationale]\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142ea500-5464-4d92-b500-1103387ef162",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def coordinator_agent(state: AcademicState) -> Dict:\n",
    "    \"\"\"\n",
    "    Primary coordinator agent that orchestrates multiple academic support agents using ReACT framework.\n",
    "\n",
    "    This agent implements a sophisticated coordination strategy:\n",
    "    1. Analyzes academic context and student needs\n",
    "    2. Uses ReACT framework for structured decision making\n",
    "    3. Coordinates parallel agent execution\n",
    "    4. Handles fallback scenarios\n",
    "\n",
    "    Args:\n",
    "        state (AcademicState): Current academic state including messages and context\n",
    "\n",
    "    Returns:\n",
    "        Dict: Coordination analysis including required agents, priorities, and execution groups\n",
    "\n",
    "    Implementation Notes:\n",
    "    -------------------\n",
    "    1. ReACT Framework Implementation:\n",
    "       - Thought: Analysis phase\n",
    "       - Action: Agent selection phase\n",
    "       - Observation: Capability evaluation\n",
    "       - Decision: Final execution planning\n",
    "\n",
    "    2. Agent Coordination Strategy:\n",
    "       - Manages three specialized agents:\n",
    "         * PLANNER: Core scheduling agent\n",
    "         * NOTEWRITER: Content creation agent\n",
    "         * ADVISOR: Academic guidance agent\n",
    "\n",
    "    3. Parallel Execution Management:\n",
    "       - Groups compatible agents\n",
    "       - Maintains execution dependencies\n",
    "       - Coordinates parallel workflows\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Analyze current context and extract latest query\n",
    "        context = await analyze_context(state)\n",
    "        query = state[\"messages\"][-1].content\n",
    "\n",
    "        # Define the ReACT-based coordination prompt\n",
    "        prompt = COORDINATOR_PROMPT\n",
    "\n",
    "        # Generate coordination plan using LLM\n",
    "        response = await llm.agenerate([\n",
    "            {\"role\": \"system\", \"content\": prompt.format(\n",
    "                request=query,\n",
    "                context=json.dumps(context, indent=2)\n",
    "            )}\n",
    "        ])\n",
    "\n",
    "        # Parse response and structure coordination analysis\n",
    "        analysis = parse_coordinator_response(response)\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"coordinator_analysis\": {\n",
    "                    \"required_agents\": analysis.get(\"required_agents\", [\"PLANNER\"]),\n",
    "                    \"priority\": analysis.get(\"priority\", {\"PLANNER\": 1}),\n",
    "                    \"concurrent_groups\": analysis.get(\"concurrent_groups\", [[\"PLANNER\"]]),\n",
    "                    \"reasoning\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Coordinator error: {e}\")\n",
    "        # Fallback to basic planning configuration\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"coordinator_analysis\": {\n",
    "                    \"required_agents\": [\"PLANNER\"],\n",
    "                    \"priority\": {\"PLANNER\": 1},\n",
    "                    \"concurrent_groups\": [[\"PLANNER\"]],\n",
    "                    \"reasoning\": \"Error in coordination. Falling back to planner.\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "def parse_coordinator_response(response: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parses LLM response into structured coordination analysis.\n",
    "\n",
    "    This function:\n",
    "    1. Starts with default safe configuration\n",
    "    2. Analyzes ReACT pattern responses\n",
    "    3. Identifies required agents and priorities\n",
    "    4. Structures concurrent execution groups\n",
    "\n",
    "    Args:\n",
    "        response (str): Raw LLM response following ReACT pattern\n",
    "\n",
    "    Returns:\n",
    "        Dict: Structured analysis for agent execution\n",
    "\n",
    "    Implementation Notes:\n",
    "    -------------------\n",
    "    1. Default Configuration:\n",
    "       - Always includes PLANNER as base agent\n",
    "       - Sets initial priority structure\n",
    "       - Defines basic execution group\n",
    "\n",
    "    2. Response Analysis:\n",
    "       - Detects ReACT pattern markers\n",
    "       - Identifies agent requirements\n",
    "       - Determines execution priorities\n",
    "\n",
    "    3. Agent Coordination:\n",
    "       - Groups compatible agents for parallel execution\n",
    "       - Sets priority levels for sequential tasks\n",
    "       - Maintains execution dependencies\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize with safe default configuration\n",
    "        analysis = {\n",
    "            \"required_agents\": [\"PLANNER\"],\n",
    "            \"priority\": {\"PLANNER\": 1},\n",
    "            \"concurrent_groups\": [[\"PLANNER\"]],\n",
    "            \"reasoning\": response\n",
    "        }\n",
    "\n",
    "        # Parse ReACT patterns for advanced coordination\n",
    "        if \"Thought:\" in response and \"Decision:\" in response:\n",
    "            # Check for NOTEWRITER requirements\n",
    "            if \"NOTEWRITER\" in response or \"note\" in response.lower():\n",
    "                analysis[\"required_agents\"].append(\"NOTEWRITER\")\n",
    "                analysis[\"priority\"][\"NOTEWRITER\"] = 2\n",
    "                # NOTEWRITER can run parallel with PLANNER\n",
    "                analysis[\"concurrent_groups\"] = [[\"PLANNER\", \"NOTEWRITER\"]]\n",
    "\n",
    "            # Check for ADVISOR requirements\n",
    "            if \"ADVISOR\" in response or \"guidance\" in response.lower():\n",
    "                analysis[\"required_agents\"].append(\"ADVISOR\")\n",
    "                analysis[\"priority\"][\"ADVISOR\"] = 3\n",
    "                # ADVISOR typically runs sequentially\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {str(e)}\")\n",
    "        # Return safe default configuration\n",
    "        return {\n",
    "            \"required_agents\": [\"PLANNER\"],\n",
    "            \"priority\": {\"PLANNER\": 1},\n",
    "            \"concurrent_groups\": [[\"PLANNER\"]],\n",
    "            \"reasoning\": \"Fallback due to parse error\"\n",
    "        }\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf2204c-af55-44a2-92fb-c63a3bde5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_ANALYZER_PROMPT = \"\"\"You are a Profile Analysis Agent using the ReACT framework to analyze student profiles.\n",
    "\n",
    "    OBJECTIVE:\n",
    "    Analyze the student profile and extract key learning patterns that will impact their academic success.\n",
    "\n",
    "    REACT PATTERN:\n",
    "    Thought: Analyze what aspects of the profile need investigation\n",
    "    Action: Extract specific information from relevant profile sections\n",
    "    Observation: Note key patterns and implications\n",
    "    Response: Provide structured analysis\n",
    "\n",
    "    PROFILE DATA:\n",
    "    {profile}\n",
    "\n",
    "    ANALYSIS FRAMEWORK:\n",
    "    1. Learning Characteristics:\n",
    "        • Primary learning style\n",
    "        • Information processing patterns\n",
    "        • Attention span characteristics\n",
    "\n",
    "    2. Environmental Factors:\n",
    "        • Optimal study environment\n",
    "        • Distraction triggers\n",
    "        • Productive time periods\n",
    "\n",
    "    3. Executive Function:\n",
    "        • Task management patterns\n",
    "        • Focus duration limits\n",
    "        • Break requirements\n",
    "\n",
    "    4. Energy Management:\n",
    "        • Peak energy periods\n",
    "        • Recovery patterns\n",
    "        • Fatigue signals\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. Use the ReACT pattern for each analysis area\n",
    "    2. Provide specific, actionable observations\n",
    "    3. Note both strengths and challenges\n",
    "    4. Identify patterns that affect study planning\n",
    "\n",
    "    FORMAT YOUR RESPONSE AS:\n",
    "    Thought: [Initial analysis of profile components]\n",
    "    Action: [Specific areas being examined]\n",
    "    Observation: [Patterns and insights discovered]\n",
    "    Analysis Summary: [Structured breakdown of key findings]\n",
    "    Recommendations: [Specific adaptations needed]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28dba2d0-da05-4a06-a385-ce005b1e6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def profile_analyzer(state: AcademicState) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyzes student profile data to extract and interpret learning preferences using ReACT framework.\n",
    "\n",
    "    This agent specializes in:\n",
    "    1. Deep analysis of student learning profiles\n",
    "    2. Extraction of learning preferences and patterns\n",
    "    3. Interpretation of academic history and tendencies\n",
    "    4. Generation of personalized learning insights\n",
    "\n",
    "    Args:\n",
    "        state (AcademicState): Current academic state containing student profile data\n",
    "\n",
    "    Returns:\n",
    "        Dict: Structured analysis results including learning preferences and recommendations\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract profile data from state\n",
    "    profile = state[\"profile\"]\n",
    "\n",
    "    # Assumes PROFILE_ANALYZER_PROMPT is defined elsewhere with ReACT framework structure\n",
    "    prompt = PROFILE_ANALYZER_PROMPT\n",
    "\n",
    "    # Construct message array for LLM interaction\n",
    "    messages = [\n",
    "        # System message defines analysis framework and expectations\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        # User message contains serialized profile data for analysis\n",
    "        {\"role\": \"user\", \"content\": json.dumps(profile)}\n",
    "    ]\n",
    "\n",
    "    # Generate analysis using LLM\n",
    "    response = await llm.agenerate(messages)\n",
    "\n",
    "    # Format and structure the analysis results\n",
    "    return {\n",
    "        \"results\": {\n",
    "            \"profile_analysis\": {\n",
    "                \"analysis\": response  # Contains structured learning preference analysis\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b63b1d0f-2def-4de5-bbb0-a76693a54fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlannerAgent(ReActAgent):\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(llm)  # Initialize parent ReActAgent class\n",
    "        self.llm = llm\n",
    "        # Load example scenarios to help guide the AI's responses\n",
    "        self.few_shot_examples = self._initialize_fewshots()\n",
    "        # Create the workflow structure\n",
    "        self.workflow = self.create_subgraph()\n",
    "\n",
    "    def _initialize_fewshots(self):\n",
    "        \"\"\"\n",
    "        Define example scenarios to help the AI understand how to handle different situations\n",
    "        Each example shows:\n",
    "        - Input: The student's request\n",
    "        - Thought: The analysis process\n",
    "        - Action: What needs to be done\n",
    "        - Observation: What was found\n",
    "        - Plan: The detailed solution\n",
    "        \"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"input\": \"Help with exam prep while managing ADHD and football\",\n",
    "                \"thought\": \"Need to check calendar conflicts and energy patterns\",\n",
    "                \"action\": \"search_calendar\",\n",
    "                \"observation\": \"Football match at 6PM, exam tomorrow 9AM\",\n",
    "                \"plan\": \"\"\"ADHD-OPTIMIZED SCHEDULE:\n",
    "                    PRE-FOOTBALL (2PM-5PM):\n",
    "                    - 3x20min study sprints\n",
    "                    - Movement breaks\n",
    "                    - Quick rewards after each sprint\n",
    "\n",
    "                    FOOTBALL MATCH (6PM-8PM):\n",
    "                    - Use as dopamine reset\n",
    "                    - Formula review during breaks\n",
    "\n",
    "                    POST-MATCH (9PM-12AM):\n",
    "                    - Environment: Café noise\n",
    "                    - 15/5 study/break cycles\n",
    "                    - Location changes hourly\n",
    "\n",
    "                    EMERGENCY PROTOCOLS:\n",
    "                    - Focus lost → jumping jacks\n",
    "                    - Overwhelmed → room change\n",
    "                    - Brain fog → cold shower\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Struggling with multiple deadlines\",\n",
    "                \"thought\": \"Check task priorities and performance issues\",\n",
    "                \"action\": \"analyze_tasks\",\n",
    "                \"observation\": \"3 assignments due, lowest grade in Calculus\",\n",
    "                \"plan\": \"\"\"PRIORITY SCHEDULE:\n",
    "                    HIGH-FOCUS SLOTS:\n",
    "                    - Morning: Calculus practice\n",
    "                    - Post-workout: Assignments\n",
    "                    - Night: Quick reviews\n",
    "\n",
    "                    ADHD MANAGEMENT:\n",
    "                    - Task timer challenges\n",
    "                    - Reward system per completion\n",
    "                    - Study buddy accountability\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    # Section 2: Create the Planning Workflow Graph and Return with compile the graph\n",
    "    def create_subgraph(self) -> StateGraph:\n",
    "        \"\"\"\n",
    "        Create a workflow graph that defines how the planner processes requests:\n",
    "        1. First analyzes calendar (calendar_analyzer)\n",
    "        2. Then analyzes tasks (task_analyzer)\n",
    "        3. Finally generates a plan (plan_generator)\n",
    "        \"\"\"\n",
    "        # Initialize a new graph using our AcademicState structure\n",
    "        subgraph = StateGraph(AcademicState)\n",
    "\n",
    "        # Add each processing step as a node in our graph\n",
    "        subgraph.add_node(\"calendar_analyzer\", self.calendar_analyzer)\n",
    "        subgraph.add_node(\"task_analyzer\", self.task_analyzer)\n",
    "        subgraph.add_node(\"plan_generator\", self.plan_generator)\n",
    "\n",
    "        # Connect the nodes in the order they should execute\n",
    "        subgraph.add_edge(\"calendar_analyzer\", \"task_analyzer\")\n",
    "        subgraph.add_edge(\"task_analyzer\", \"plan_generator\")\n",
    "\n",
    "        # Set where the workflow begins\n",
    "        subgraph.set_entry_point(\"calendar_analyzer\")\n",
    "\n",
    "        # Prepare the graph for use\n",
    "        return subgraph.compile()\n",
    "\n",
    "    async def calendar_analyzer(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"\n",
    "        Analyze the student's calendar to find:\n",
    "        - Available study times\n",
    "        - Potential scheduling conflicts\n",
    "        - Energy patterns throughout the day\n",
    "        \"\"\"\n",
    "        # Get calendar events for the next 7 days\n",
    "        events = state[\"calendar\"].get(\"events\", [])\n",
    "        now = datetime.now(timezone.utc)\n",
    "        future = now + timedelta(days=7)\n",
    "\n",
    "        # Filter to only include upcoming events\n",
    "        filtered_events = [\n",
    "            event for event in events\n",
    "            if now <= datetime.fromisoformat(event[\"start\"][\"dateTime\"]) <= future\n",
    "        ]\n",
    "\n",
    "        # Create prompt for the AI to analyze the calendar\n",
    "        prompt = \"\"\"Analyze calendar events and identify:\n",
    "        Events: {events}\n",
    "\n",
    "        Focus on:\n",
    "        - Available time blocks\n",
    "        - Energy impact of activities\n",
    "        - Potential conflicts\n",
    "        - Recovery periods\n",
    "        - Study opportunity windows\n",
    "        - Activity patterns\n",
    "        - Schedule optimization\n",
    "        \"\"\"\n",
    "\n",
    "        # Ask AI to analyze the calendar\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(filtered_events)}\n",
    "        ]\n",
    "\n",
    "        response = await self.llm.agenerate(messages)\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "        # Return the analysis results\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"calendar_analysis\": {\n",
    "                    \"analysis\":response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    async def task_analyzer(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"\n",
    "        Analyze tasks to determine:\n",
    "        - Priority order\n",
    "        - Time needed for each task\n",
    "        - Best approach for completion\n",
    "        \"\"\"\n",
    "        tasks = state[\"tasks\"].get(\"tasks\", [])\n",
    "\n",
    "        # Create prompt for AI to analyze tasks\n",
    "        prompt = \"\"\"Analyze tasks and create priority structure:\n",
    "        Tasks: {tasks}\n",
    "\n",
    "        Consider:\n",
    "        - Urgency levels\n",
    "        - Task complexity\n",
    "        - Energy requirements\n",
    "        - Dependencies\n",
    "        - Required focus levels\n",
    "        - Time estimations\n",
    "        - Learning objectives\n",
    "        - Success criteria\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(tasks)}\n",
    "        ]\n",
    "\n",
    "        response = await self.llm.agenerate(messages)\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"task_analysis\": {\n",
    "                    \"analysis\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def plan_generator(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"\n",
    "        Create a comprehensive study plan by combining:\n",
    "        - Profile analysis (student's learning style)\n",
    "        - Calendar analysis (available time)\n",
    "        - Task analysis (what needs to be done)\n",
    "        \"\"\"\n",
    "        # Gather all previous analyses\n",
    "        profile_analysis = state[\"results\"][\"profile_analysis\"]\n",
    "        calendar_analysis = state[\"results\"][\"calendar_analysis\"]\n",
    "        task_analysis = state[\"results\"][\"task_analysis\"]\n",
    "\n",
    "        # Create detailed prompt for AI to generate plan\n",
    "        prompt = f\"\"\"AI Planning Assistant: Create focused study plan using ReACT framework.\n",
    "\n",
    "          INPUT CONTEXT:\n",
    "          - Profile Analysis: {profile_analysis}\n",
    "          - Calendar Analysis: {calendar_analysis}\n",
    "          - Task Analysis: {task_analysis}\n",
    "\n",
    "          EXAMPLES:\n",
    "          {json.dumps(self.few_shot_examples, indent=2)}\n",
    "\n",
    "          INSTRUCTIONS:\n",
    "          1. Follow ReACT pattern:\n",
    "            Thought: Analyze situation and needs\n",
    "            Action: Consider all analyses\n",
    "            Observation: Synthesize findings\n",
    "            Plan: Create structured plan\n",
    "\n",
    "          2. Address:\n",
    "            - ADHD management strategies\n",
    "            - Energy level optimization\n",
    "            - Task chunking methods\n",
    "            - Focus period scheduling\n",
    "            - Environment switching tactics\n",
    "            - Recovery period planning\n",
    "            - Social/sport activity balance\n",
    "\n",
    "          3. Include:\n",
    "            - Emergency protocols\n",
    "            - Backup strategies\n",
    "            - Quick wins\n",
    "            - Reward system\n",
    "            - Progress tracking\n",
    "            - Adjustment triggers\n",
    "\n",
    "          Pls act as an intelligent tool to help the students reach their goals or overcome struggles and answer with informal words.\n",
    "\n",
    "          FORMAT:\n",
    "          Thought: [reasoning and situation analysis]\n",
    "          Action: [synthesis approach]\n",
    "          Observation: [key findings]\n",
    "          Plan: [actionable steps and structural schedule]\n",
    "          \"\"\"\n",
    "\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": state[\"messages\"][-1].content}\n",
    "        ]\n",
    "        # temperature is like a randomness of LLM response, 0.5 is in the middle\n",
    "        response = await self.llm.agenerate(messages, temperature=0.5)\n",
    "\n",
    "        # Clean the response before returning\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "        return {\n",
    "                \"results\": {\n",
    "                    \"final_plan\": {\n",
    "                        \"plan\": response\n",
    "                    }\n",
    "                }\n",
    "        }\n",
    "\n",
    "    async def __call__(self, state: AcademicState) -> Dict:\n",
    "        \"\"\"\n",
    "        Main execution method that runs the entire planning workflow:\n",
    "        1. Analyze calendar\n",
    "        2. Analyze tasks\n",
    "        3. Generate plan\n",
    "        \"\"\"\n",
    "        try:\n",
    "            final_state = await self.workflow.ainvoke(state)\n",
    "            # Clean the generated notes before returning\n",
    "            notes = final_state[\"results\"].get(\"generated_notes\", {})\n",
    "            #cleaned_notes = clean_llm_output({\"notes\": notes})\n",
    "            return {\"notes\": final_state[\"results\"].get(\"generated_notes\")}\n",
    "            #return {\"notes\": cleaned_notes.get(\"notes\")}\n",
    "        except Exception as e:\n",
    "            return {\"notes\": \"Error generating notes. Please try again.\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18a4a25b-9751-4b34-9acc-d542033a4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteWriterAgent(ReActAgent):\n",
    "    \"\"\"NoteWriter agent with its own subgraph workflow for note generation.\n",
    "    This agent specializes in creating personalized study materials by analyzing\n",
    "    learning styles and generating structured notes.\"\"\"\n",
    "\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"Initialize the NoteWriter agent with an LLM backend and example templates.\n",
    "\n",
    "        Args:\n",
    "            llm: Language model instance for text generation\n",
    "        \"\"\"\n",
    "        super().__init__(llm)\n",
    "        self.llm = llm\n",
    "        self.few_shot_examples = [\n",
    "            {\n",
    "                \"input\": \"Need to cram Calculus III for tomorrow\",\n",
    "                \"template\": \"Quick Review\",\n",
    "                \"notes\": \"\"\"CALCULUS III ESSENTIALS:\n",
    "\n",
    "                1. CORE CONCEPTS (80/20 Rule):\n",
    "                   • Multiple Integrals → volume/area\n",
    "                   • Vector Calculus → flow/force/rotation\n",
    "                   • KEY FORMULAS:\n",
    "                     - Triple integrals in cylindrical/spherical coords\n",
    "                     - Curl, divergence, gradient relationships\n",
    "\n",
    "                2. COMMON EXAM PATTERNS:\n",
    "                   • Find critical points\n",
    "                   • Calculate flux/work\n",
    "                   • Optimize with constraints\n",
    "\n",
    "                3. QUICKSTART GUIDE:\n",
    "                   • Always draw 3D diagrams\n",
    "                   • Check units match\n",
    "                   • Use symmetry to simplify\n",
    "\n",
    "                4. EMERGENCY TIPS:\n",
    "                   • If stuck, try converting coordinates\n",
    "                   • Check boundary conditions\n",
    "                   • Look for special patterns\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        self.workflow = self.create_subgraph()\n",
    "\n",
    "    def create_subgraph(self) -> StateGraph:\n",
    "        \"\"\"Creates NoteWriter's internal workflow as a state machine.\n",
    "\n",
    "        The workflow consists of two main steps:\n",
    "        1. Analyze learning style and content requirements\n",
    "        2. Generate personalized notes\n",
    "\n",
    "        Returns:\n",
    "            StateGraph: Compiled workflow graph\n",
    "        \"\"\"\n",
    "        subgraph = StateGraph(AcademicState)\n",
    "\n",
    "        # Define the core workflow nodes\n",
    "        subgraph.add_node(\"notewriter_analyze\", self.analyze_learning_style)\n",
    "        subgraph.add_node(\"notewriter_generate\", self.generate_notes)\n",
    "\n",
    "        # Create the workflow sequence:\n",
    "        # START -> analyze -> generate -> END\n",
    "        subgraph.add_edge(START, \"notewriter_analyze\")\n",
    "        subgraph.add_edge(\"notewriter_analyze\", \"notewriter_generate\")\n",
    "        subgraph.add_edge(\"notewriter_generate\", END)\n",
    "\n",
    "        return subgraph.compile()\n",
    "\n",
    "    async def analyze_learning_style(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"Analyzes student profile and request to determine optimal note structure.\n",
    "\n",
    "        Uses the LLM to analyze:\n",
    "        - Student's learning style preferences\n",
    "        - Specific content request\n",
    "        - Time constraints and requirements\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state containing student profile and messages\n",
    "\n",
    "        Returns:\n",
    "            Updated state with learning analysis results\n",
    "        \"\"\"\n",
    "        profile = state[\"profile\"]\n",
    "        learning_style = profile[\"learning_preferences\"][\"learning_style\"]\n",
    "        # Construct analysis prompt with specific formatting requirements\n",
    "\n",
    "        prompt = f\"\"\"Analyze content requirements and determine optimal note structure:\n",
    "\n",
    "        STUDENT PROFILE:\n",
    "        - Learning Style: {json.dumps(learning_style, indent=2)}\n",
    "        - Request: {state['messages'][-1].content}\n",
    "\n",
    "        FORMAT:\n",
    "        1. Key Topics (80/20 principle)\n",
    "        2. Learning Style Adaptations\n",
    "        3. Time Management Strategy\n",
    "        4. Quick Reference Format\n",
    "\n",
    "        FOCUS ON:\n",
    "        - Essential concepts that give maximum understanding\n",
    "        - Visual and interactive elements\n",
    "        - Time-optimized study methods\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.llm.agenerate([\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ])\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"learning_analysis\": {\n",
    "                    \"analysis\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def generate_notes(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"Generates personalized study notes based on the learning analysis.\n",
    "\n",
    "        Uses the LLM to create structured notes that are:\n",
    "        - Adapted to the student's learning style\n",
    "        - Focused on essential concepts (80/20 principle)\n",
    "        - Time-optimized for the study period\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state with learning analysis\n",
    "        Returns:\n",
    "            Updated state with generated notes\n",
    "        \"\"\"\n",
    "\n",
    "        analysis = state[\"results\"].get(\"learning_analysis\", \"\")\n",
    "        learning_style = state[\"profile\"][\"learning_preferences\"][\"learning_style\"]\n",
    "\n",
    "        # Build prompt using analysis and few-shot examples\n",
    "        prompt = f\"\"\"Create concise, high-impact study materials based on analysis:\n",
    "\n",
    "        ANALYSIS: {analysis}\n",
    "        LEARNING STYLE: {json.dumps(learning_style, indent=2)}\n",
    "        REQUEST: {state['messages'][-1].content}\n",
    "\n",
    "        EXAMPLES:\n",
    "        {json.dumps(self.few_shot_examples, indent=2)}\n",
    "\n",
    "        FORMAT:\n",
    "        **THREE-WEEK INTENSIVE STUDY PLANNER**\n",
    "\n",
    "        [Generate structured notes with:]\n",
    "        1. Weekly breakdown\n",
    "        2. Daily focus areas\n",
    "        3. Core concepts\n",
    "        4. Emergency tips\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.llm.agenerate([\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ])\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "        # if \"results\" not in state:\n",
    "        #     state[\"results\"] = {}\n",
    "        # state[\"results\"][\"generated_notes\"] = response\n",
    "        # return state\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"generated_notes\": {\n",
    "                    \"notes\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    async def __call__(self, state: AcademicState) -> Dict:\n",
    "        \"\"\"Main execution method for the NoteWriter agent.\n",
    "\n",
    "        Executes the complete workflow:\n",
    "        1. Analyzes learning requirements\n",
    "        2. Generates personalized notes\n",
    "        3. Cleans and returns the results\n",
    "\n",
    "        Args:\n",
    "            state: Initial academic state\n",
    "\n",
    "        Returns:\n",
    "            Dict containing generated notes or error message\n",
    "        \"\"\"\n",
    "        try:\n",
    "            final_state = await self.workflow.ainvoke(state)\n",
    "            # Clean the generated notes before returning\n",
    "            notes = final_state[\"results\"].get(\"generated_notes\", {})\n",
    "            #cleaned_notes = clean_llm_output({\"notes\": notes})\n",
    "            return {\"notes\": final_state[\"results\"].get(\"generated_notes\")}\n",
    "            #return {\"notes\": cleaned_notes.get(\"notes\")}\n",
    "        except Exception as e:\n",
    "            return {\"notes\": \"Error generating notes. Please try again.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b674d941-a5c0-4667-8538-07583f8a81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvisorAgent(ReActAgent):\n",
    "    \"\"\"Academic advisor agent with subgraph workflow for personalized guidance.\n",
    "    This agent specializes in analyzing student situations and providing\n",
    "    tailored academic advice considering learning styles and time constraints.\"\"\"\n",
    "\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"Initialize the Advisor agent with an LLM backend and example templates.\n",
    "\n",
    "        Args:\n",
    "            llm: Language model instance for text generation\n",
    "        \"\"\"\n",
    "        super().__init__(llm)\n",
    "        self.llm = llm\n",
    "\n",
    "        # Define comprehensive examples for guidance generation\n",
    "        # These examples help the LLM understand the expected format and depth\n",
    "        self.few_shot_examples = [\n",
    "            {\n",
    "                \"request\": \"Managing multiple deadlines with limited time\",\n",
    "                \"profile\": {\n",
    "                    \"learning_style\": \"visual\",\n",
    "                    \"workload\": \"heavy\",\n",
    "                    \"time_constraints\": [\"2 hackathons\", \"project\", \"exam\"]\n",
    "                },\n",
    "                \"advice\": \"\"\"PRIORITY-BASED SCHEDULE:\n",
    "\n",
    "                1. IMMEDIATE ACTIONS\n",
    "                   • Create visual timeline of all deadlines\n",
    "                   • Break each task into 45-min chunks\n",
    "                   • Schedule high-focus work in mornings\n",
    "\n",
    "                2. WORKLOAD MANAGEMENT\n",
    "                   • Hackathons: Form team early, set clear roles\n",
    "                   • Project: Daily 2-hour focused sessions\n",
    "                   • Exam: Interleaved practice with breaks\n",
    "\n",
    "                3. ENERGY OPTIMIZATION\n",
    "                   • Use Pomodoro (25/5) for intensive tasks\n",
    "                   • Physical activity between study blocks\n",
    "                   • Regular progress tracking\n",
    "\n",
    "                4. EMERGENCY PROTOCOLS\n",
    "                   • If overwhelmed: Take 10min reset break\n",
    "                   • If stuck: Switch tasks or environments\n",
    "                   • If tired: Quick power nap, then review\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        # Initialize the agent's workflow state machine\n",
    "        self.workflow = self.create_subgraph()\n",
    "\n",
    "    def create_subgraph(self) -> StateGraph:\n",
    "      \"\"\"Creates Advisor's internal workflow as a state machine.\n",
    "\n",
    "        The workflow consists of two main stages:\n",
    "        1. Situation analysis - Understanding student needs\n",
    "        2. Guidance generation - Creating personalized advice\n",
    "\n",
    "        Returns:\n",
    "            StateGraph: Compiled workflow graph\n",
    "      \"\"\"\n",
    "      subgraph = StateGraph(AcademicState)\n",
    "\n",
    "      # Add nodes for analysis and guidance - use consistent names\n",
    "      subgraph.add_node(\"advisor_analyze\", self.analyze_situation)\n",
    "      subgraph.add_node(\"advisor_generate\", self.generate_guidance)\n",
    "\n",
    "      # Connect workflow - use the new node names\n",
    "      subgraph.add_edge(START, \"advisor_analyze\")\n",
    "      subgraph.add_edge(\"advisor_analyze\", \"advisor_generate\")\n",
    "      subgraph.add_edge(\"advisor_generate\", END)\n",
    "\n",
    "      return subgraph.compile()\n",
    "\n",
    "    async def analyze_situation(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"Analyzes student's current academic situation and needs.\n",
    "\n",
    "        Evaluates:\n",
    "        - Student profile and preferences\n",
    "        - Current challenges and constraints\n",
    "        - Learning style compatibility\n",
    "        - Time and stress management needs\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state with student profile and request\n",
    "\n",
    "        Returns:\n",
    "            Updated state with situation analysis results\n",
    "        \"\"\"\n",
    "        profile = state[\"profile\"]\n",
    "        learning_prefs = profile.get(\"learning_preferences\", {})\n",
    "\n",
    "        prompt = f\"\"\"Analyze student situation and determine guidance approach:\n",
    "\n",
    "        CONTEXT:\n",
    "        - Profile: {json.dumps(profile, indent=2)}\n",
    "        - Learning Preferences: {json.dumps(learning_prefs, indent=2)}\n",
    "        - Request: {state['messages'][-1].content}\n",
    "\n",
    "        ANALYZE:\n",
    "        1. Current challenges\n",
    "        2. Learning style compatibility\n",
    "        3. Time management needs\n",
    "        4. Stress management requirements\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.llm.agenerate([\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ])\n",
    "\n",
    "        # if \"results\" not in state:\n",
    "        #     state[\"results\"] = {}\n",
    "        # state[\"results\"][\"situation_analysis\"] = response\n",
    "        # return state\n",
    "        #Clean the response before returning\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"situation_analysis\": {\n",
    "                    \"analysis\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def generate_guidance(self, state: AcademicState) -> AcademicState:\n",
    "        \"\"\"Generates personalized academic guidance based on situation analysis.\n",
    "\n",
    "        Creates structured advice focusing on:\n",
    "        - Immediate actionable steps\n",
    "        - Schedule optimization\n",
    "        - Energy and resource management\n",
    "        - Support strategies\n",
    "        - Contingency planning\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state with situation analysis\n",
    "\n",
    "        Returns:\n",
    "            Updated state with generated guidance\n",
    "        \"\"\"\n",
    "\n",
    "        analysis = state[\"results\"].get(\"situation_analysis\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"Generate personalized academic guidance based on analysis:\n",
    "\n",
    "        ANALYSIS: {analysis}\n",
    "        EXAMPLES: {json.dumps(self.few_shot_examples, indent=2)}\n",
    "\n",
    "        FORMAT:\n",
    "        1. Immediate Action Steps\n",
    "        2. Schedule Optimization\n",
    "        3. Energy Management\n",
    "        4. Support Strategies\n",
    "        5. Emergency Protocols\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.llm.agenerate([\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ])\n",
    "\n",
    "        # if \"results\" not in state:\n",
    "        #     state[\"results\"] = {}\n",
    "        # state[\"results\"][\"guidance\"] = response\n",
    "        # return state\n",
    "        #cleaned_response = clean_llm_output({\"response\": response})\n",
    "\n",
    "        return {\n",
    "            \"results\": {\n",
    "                \"guidance\": {\n",
    "                    \"advice\": response\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def __call__(self, state: AcademicState) -> Dict:\n",
    "        \"\"\"Main execution method for the Advisor agent.\n",
    "\n",
    "        Executes the complete advisory workflow:\n",
    "        1. Analyzes student situation\n",
    "        2. Generates personalized guidance\n",
    "        3. Returns formatted results with metadata\n",
    "\n",
    "        Args:\n",
    "            state: Initial academic state\n",
    "\n",
    "        Returns:\n",
    "            Dict containing guidance and metadata or error message\n",
    "\n",
    "        Note:\n",
    "            Includes metadata about guidance specificity and learning style consideration\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            final_state = await self.workflow.ainvoke(state)\n",
    "            return {\n",
    "                \"advisor_output\": {\n",
    "                    \"guidance\": final_state[\"results\"].get(\"guidance\"),\n",
    "                    \"metadata\": {\n",
    "                        \"course_specific\": True,\n",
    "                        \"considers_learning_style\": True\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"advisor_output\": {\n",
    "                    \"guidance\": \"Error generating guidance. Please try again.\"\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eca9818-58f0-495a-befb-303979ec2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agents_graph(llm) -> StateGraph:\n",
    "    \"\"\"Creates a coordinated workflow graph for multiple AI agents.\n",
    "\n",
    "    This orchestration system manages parallel execution of three specialized agents:\n",
    "    - PlannerAgent: Handles scheduling and calendar management\n",
    "    - NoteWriterAgent: Creates personalized study materials\n",
    "    - AdvisorAgent: Provides academic guidance and support\n",
    "\n",
    "    The workflow uses a state machine approach with conditional routing based on\n",
    "    analysis of student needs.\n",
    "\n",
    "    Args:\n",
    "        llm: Language model instance shared across all agents\n",
    "\n",
    "    Returns:\n",
    "        StateGraph: Compiled workflow graph with parallel execution paths\n",
    "    \"\"\"\n",
    "    # Initialize main workflow state machine\n",
    "    workflow = StateGraph(AcademicState)\n",
    "\n",
    "    # Create instances of our specialized agents\n",
    "    # Each agent has its own subgraph for internal operations\n",
    "    planner_agent = PlannerAgent(llm)\n",
    "    notewriter_agent = NoteWriterAgent(llm)\n",
    "    advisor_agent = AdvisorAgent(llm)\n",
    "    executor = AgentExecutor(llm)\n",
    "\n",
    "    # === MAIN WORKFLOW NODES ===\n",
    "    # These nodes handle high-level coordination and analysis\n",
    "    workflow.add_node(\"coordinator\", coordinator_agent)  # Initial request analysis\n",
    "    workflow.add_node(\"profile_analyzer\", profile_analyzer)  # Student profile analysis\n",
    "    workflow.add_node(\"execute\", executor.execute)  # Final execution node\n",
    "\n",
    "    # === PARALLEL EXECUTION ROUTING ===\n",
    "    def route_to_parallel_agents(state: AcademicState) -> List[str]:\n",
    "        \"\"\"Determines which agents should process the current request.\n",
    "\n",
    "        Analyzes coordinator's output to route work to appropriate agents.\n",
    "        Defaults to planner if no specific agents are required.\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state with coordinator analysis\n",
    "\n",
    "        Returns:\n",
    "            List of next node names to execute\n",
    "        \"\"\"\n",
    "        analysis = state[\"results\"].get(\"coordinator_analysis\", {})\n",
    "        required_agents = analysis.get(\"required_agents\", [])\n",
    "        next_nodes = []\n",
    "\n",
    "        # Route to appropriate agent entry points based on analysis\n",
    "        if \"PLANNER\" in required_agents:\n",
    "            next_nodes.append(\"calendar_analyzer\")\n",
    "        if \"NOTEWRITER\" in required_agents:\n",
    "            next_nodes.append(\"notewriter_analyze\")\n",
    "        if \"ADVISOR\" in required_agents:\n",
    "            next_nodes.append(\"advisor_analyze\")\n",
    "\n",
    "        # Default to planner if no specific agents requested\n",
    "        return next_nodes if next_nodes else [\"calendar_analyzer\"]\n",
    "\n",
    "    # === AGENT SUBGRAPH NODES ===\n",
    "    # Add nodes for Planner agent's workflow\n",
    "    workflow.add_node(\"calendar_analyzer\", planner_agent.calendar_analyzer)\n",
    "    workflow.add_node(\"task_analyzer\", planner_agent.task_analyzer)\n",
    "    workflow.add_node(\"plan_generator\", planner_agent.plan_generator)\n",
    "\n",
    "    # Add nodes for NoteWriter agent's workflow\n",
    "    workflow.add_node(\"notewriter_analyze\", notewriter_agent.analyze_learning_style)\n",
    "    workflow.add_node(\"notewriter_generate\", notewriter_agent.generate_notes)\n",
    "\n",
    "    # Add nodes for Advisor agent's workflow\n",
    "    workflow.add_node(\"advisor_analyze\", advisor_agent.analyze_situation)\n",
    "    workflow.add_node(\"advisor_generate\", advisor_agent.generate_guidance)\n",
    "\n",
    "    # === WORKFLOW CONNECTIONS ===\n",
    "    # Main workflow entry\n",
    "    workflow.add_edge(START, \"coordinator\")\n",
    "    workflow.add_edge(\"coordinator\", \"profile_analyzer\")\n",
    "\n",
    "    # Connect profile analyzer to potential parallel paths\n",
    "    workflow.add_conditional_edges(\n",
    "        \"profile_analyzer\",\n",
    "        route_to_parallel_agents,\n",
    "        [\"calendar_analyzer\", \"notewriter_analyze\", \"advisor_analyze\"]\n",
    "    )\n",
    "\n",
    "    # Connect Planner agent's internal workflow\n",
    "    workflow.add_edge(\"calendar_analyzer\", \"task_analyzer\")\n",
    "    workflow.add_edge(\"task_analyzer\", \"plan_generator\")\n",
    "    workflow.add_edge(\"plan_generator\", \"execute\")\n",
    "\n",
    "    # Connect NoteWriter agent's internal workflow\n",
    "    workflow.add_edge(\"notewriter_analyze\", \"notewriter_generate\")\n",
    "    workflow.add_edge(\"notewriter_generate\", \"execute\")\n",
    "\n",
    "    # Connect Advisor agent's internal workflow\n",
    "    workflow.add_edge(\"advisor_analyze\", \"advisor_generate\")\n",
    "    workflow.add_edge(\"advisor_generate\", \"execute\")\n",
    "\n",
    "    # === WORKFLOW COMPLETION CHECKING ===\n",
    "    def should_end(state) -> Union[Literal[\"coordinator\"], Literal[END]]:\n",
    "        \"\"\"Determines if all required agents have completed their tasks.\n",
    "\n",
    "        Compares the set of completed agent outputs against required agents\n",
    "        to decide whether to end or continue the workflow.\n",
    "\n",
    "        Args:\n",
    "            state: Current academic state\n",
    "\n",
    "        Returns:\n",
    "            Either \"coordinator\" to continue or END to finish\n",
    "        \"\"\"\n",
    "        analysis = state[\"results\"].get(\"coordinator_analysis\", {})\n",
    "        executed = set(state[\"results\"].get(\"agent_outputs\", {}).keys())\n",
    "        required = set(a.lower() for a in analysis.get(\"required_agents\", []))\n",
    "        return END if required.issubset(executed) else \"coordinator\"\n",
    "\n",
    "    # Add conditional loop back to coordinator if needed\n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute\",\n",
    "        should_end,\n",
    "        {\n",
    "            \"coordinator\": \"coordinator\",  # Loop back if more work needed\n",
    "            END: END  # End workflow if all agents complete\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compile and return the complete workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc63d11f-cea7-4e32-a1f9-af844d615fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_all_system(profile_json: str, calendar_json: str, task_json: str):\n",
    "    \"\"\"Run the entire academic assistance system with improved output handling.\n",
    "\n",
    "    This is the main entry point for the ATLAS (Academic Task Learning Agent System).\n",
    "    It handles initialization, user interaction, workflow execution, and result presentation.\n",
    "\n",
    "    Args:\n",
    "        profile_json: JSON string containing student profile data\n",
    "        calendar_json: JSON string containing calendar/schedule data\n",
    "        task_json: JSON string containing academic tasks data\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict, Dict]: Coordinator output and final state, or (None, None) on error\n",
    "\n",
    "    Features:\n",
    "        - Rich console interface with status updates\n",
    "        - Async streaming of workflow steps\n",
    "        - Comprehensive error handling\n",
    "        - Live progress feedback\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize rich console for enhanced UI\n",
    "        console = Console()\n",
    "\n",
    "        # Display welcome banner\n",
    "        console.print(\"\\n[bold magenta]🎓 ATLAS: Academic Task Learning Agent System[/bold magenta]\")\n",
    "        console.print(\"[italic blue]Initializing academic support system...[/italic blue]\\n\")\n",
    "\n",
    "        # Initialize core system components\n",
    "        # NeMoLLaMa is the language model backend\n",
    "        llm = NeMoLLaMa(NEMOTRON_4_340B_INSTRUCT_KEY)\n",
    "\n",
    "        # DataManager handles all data loading and access\n",
    "        dm = DataManager()\n",
    "        dm.load_data(profile_json, calendar_json, task_json)\n",
    "\n",
    "        # Get user request\n",
    "        console.print(\"[bold green]Please enter your academic request:[/bold green]\")\n",
    "        user_input = str(input())\n",
    "        console.print(f\"\\n[dim italic]Processing request: {user_input}[/dim italic]\\n\")\n",
    "\n",
    "        # Construct initial state object\n",
    "        # This contains all context needed by the agents\n",
    "        state = {\n",
    "            \"messages\": [HumanMessage(content=user_input)],  # User request\n",
    "            \"profile\": dm.get_student_profile(\"student_123\"),  # Student info\n",
    "            \"calendar\": {\"events\": dm.get_upcoming_events()},  # Schedule\n",
    "            \"tasks\": {\"tasks\": dm.get_active_tasks()},        # Active tasks\n",
    "            \"results\": {}                                     # Will store agent outputs\n",
    "        }\n",
    "\n",
    "        # Initialize workflow graph for agent orchestration\n",
    "        graph = create_agents_graph(llm)\n",
    "\n",
    "        console.print(\"[bold cyan]System initialized and processing request...[/bold cyan]\\n\")\n",
    "        # Add visualization here\n",
    "        console.print(\"[bold cyan]Workflow Graph Structure:[/bold cyan]\\n\")\n",
    "        display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "        # Track important state transitions\n",
    "        coordinator_output = None  # Initial analysis\n",
    "        final_state = None        # Final results\n",
    "\n",
    "        # Process workflow with live status updates\n",
    "        with console.status(\"[bold green]Processing...\", spinner=\"dots\") as status:\n",
    "            # Stream workflow steps asynchronously\n",
    "            async for step in graph.astream(state):\n",
    "                # Capture coordinator analysis when available\n",
    "                if \"coordinator_analysis\" in step.get(\"results\", {}):\n",
    "                    coordinator_output = step\n",
    "                    analysis = coordinator_output[\"results\"][\"coordinator_analysis\"]\n",
    "\n",
    "                    # Display selected agents for transparency\n",
    "                    console.print(\"\\n[bold cyan]Selected Agents:[/bold cyan]\")\n",
    "                    for agent in analysis.get(\"required_agents\", []):\n",
    "                        console.print(f\"• {agent}\")\n",
    "\n",
    "                # Capture final execution state\n",
    "                if \"execute\" in step:\n",
    "                    final_state = step\n",
    "\n",
    "        # # Display formatted results if available\n",
    "        # if final_state:\n",
    "        #     display_formatted_output(final_state)\n",
    "        # Replace with simpler console output:\n",
    "        if final_state:\n",
    "            agent_outputs = final_state.get(\"execute\", {}).get(\"results\", {}).get(\"agent_outputs\", {})\n",
    "\n",
    "            # Simple console output for each agent\n",
    "            for agent, output in agent_outputs.items():\n",
    "                console.print(f\"\\n[bold cyan]{agent.upper()} Output:[/bold cyan]\")\n",
    "\n",
    "                # Handle nested dictionary output\n",
    "                if isinstance(output, dict):\n",
    "                    for key, value in output.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            for subkey, subvalue in value.items():\n",
    "                                if subvalue and isinstance(subvalue, str):\n",
    "                                    console.print(subvalue.strip())\n",
    "                        elif value and isinstance(value, str):\n",
    "                            console.print(value.strip())\n",
    "                # Handle direct string output\n",
    "                elif isinstance(output, str):\n",
    "                    console.print(output.strip())\n",
    "\n",
    "        # Indicate completion\n",
    "        console.print(\"\\n[bold green]✓[/bold green] [bold]Task completed![/bold]\")\n",
    "        return coordinator_output, final_state\n",
    "\n",
    "    except Exception as e:\n",
    "        # Comprehensive error handling with stack trace\n",
    "        console.print(f\"\\n[bold red]System error:[/bold red] {str(e)}\")\n",
    "        console.print(\"[yellow]Stack trace:[/yellow]\")\n",
    "        import traceback\n",
    "        console.print(traceback.format_exc())\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5a0302-5be6-4e2a-a8e6-68950175179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic Assistant Test Setup\n",
      "--------------------------------------------------\n",
      "\n",
      "Files found:\n",
      "- profile: profile.json\n",
      "- calendar: calendar.json\n",
      "- task: task.json\n",
      "\n",
      "Starting academic assistance workflow...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">🎓 ATLAS: Academic Task Learning Agent System</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m🎓 ATLAS: Academic Task Learning Agent System\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">Initializing academic support system...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;34mInitializing academic support system\u001b[0m\u001b[3;34m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Please enter your academic request:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mPlease enter your academic request:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I do 2 hackathons, and the college project about software this month, and the final exam is coming in 3 weeks. How can i overcome this shit?? Please create a planner for me based on a fixed schedule. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-style: italic\">Processing request: I do </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold; font-style: italic\">2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-style: italic\"> hackathons, and the college project about software this month, and the final exam is </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-style: italic\">coming in </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold; font-style: italic\">3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-style: italic\"> weeks. How can i overcome this shit?? Please create a planner for me based on a fixed schedule. </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[2;3mProcessing request: I do \u001b[0m\u001b[1;2;3;36m2\u001b[0m\u001b[2;3m hackathons, and the college project about software this month, and the final exam is \u001b[0m\n",
       "\u001b[2;3mcoming in \u001b[0m\u001b[1;2;3;36m3\u001b[0m\u001b[2;3m weeks. How can i overcome this shit?? Please create a planner for me based on a fixed schedule. \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not process event due to 'start'\n",
      "Warning: Could not process event due to 'start'\n",
      "Warning: Could not process event due to 'start'\n",
      "Warning: Could not process task due to 'due'\n",
      "Warning: Could not process task due to 'due'\n",
      "Warning: Could not process task due to 'due'\n",
      "Warning: Could not process task due to 'due'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">System initialized and processing request...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSystem initialized and processing request\u001b[0m\u001b[1;36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Workflow Graph Structure:</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mWorkflow Graph Structure:\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad786acc4dd45dda9d97597334a0c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Coordinator error: Error code: 401 - {'status': 401, 'title': 'Unauthorized', 'detail': 'Authentication failed'}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Coordinator error: Error code: 401 - {'status': 401, 'title': 'Unauthorized', 'detail': 'Authentication failed'}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">System error:</span> Error code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span> - <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Unauthorized'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'detail'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Authentication failed'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;31mSystem error:\u001b[0m Error code: \u001b[1;36m401\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'status'\u001b[0m: \u001b[1;36m401\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'Unauthorized'\u001b[0m, \u001b[32m'detail'\u001b[0m: \u001b[32m'Authentication failed'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Stack trace:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mStack trace:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\2714013181.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>, in run_all_system\n",
       "    async for step in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">graph.astream</span><span style=\"font-weight: bold\">(</span>state<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1411</span>, \n",
       "in astream\n",
       "    async for _ in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">runner.atick</span><span style=\"font-weight: bold\">(</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span>, in \n",
       "atick\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_panic_or_proceed</span><span style=\"font-weight: bold\">(</span>all_futures, asyncio.TimeoutError<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">186</span>, in \n",
       "_panic_or_proceed\n",
       "    raise exc\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>, in \n",
       "arun_with_retry\n",
       "    await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">task.proc.ainvoke</span><span style=\"font-weight: bold\">(</span>task.input, task.config<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">383</span>, in \n",
       "ainvoke\n",
       "    input = await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">asyncio.create_task</span><span style=\"font-weight: bold\">(</span>coro, <span style=\"color: #808000; text-decoration-color: #808000\">context</span>=<span style=\"color: #800080; text-decoration-color: #800080\">context</span><span style=\"font-weight: bold\">)</span>\n",
       "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168</span>, in \n",
       "ainvoke\n",
       "    ret = await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">asyncio.create_task</span><span style=\"font-weight: bold\">(</span>\n",
       "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\553315941.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>, in profile_analyzer\n",
       "    response = await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">llm.agenerate</span><span style=\"font-weight: bold\">(</span>messages<span style=\"font-weight: bold\">)</span>\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\2280079859.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>, in agenerate\n",
       "    completion = await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.client.chat.completions.create</span><span style=\"font-weight: bold\">(</span>\n",
       "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\"</span>, line\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1661</span>, in create\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._post</span><span style=\"font-weight: bold\">(</span>\n",
       "           ^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1843</span>, in post\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.request</span><span style=\"font-weight: bold\">(</span>cast_to, opts, <span style=\"color: #808000; text-decoration-color: #808000\">stream</span>=<span style=\"color: #800080; text-decoration-color: #800080\">stream</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stream_cls</span>=<span style=\"color: #800080; text-decoration-color: #800080\">stream_cls</span><span style=\"font-weight: bold\">)</span>\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span>, in \n",
       "request\n",
       "    return await <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._request</span><span style=\"font-weight: bold\">(</span>\n",
       "           ^^^^^^^^^^^^^^^^^^^^\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1638</span>, in \n",
       "_request\n",
       "    raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._make_status_error_from_response</span><span style=\"font-weight: bold\">(</span>err.response<span style=\"font-weight: bold\">)</span> from <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "openai.AuthenticationError: Error code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span> - <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Unauthorized'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'detail'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Authentication </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">failed'</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\2714013181.py\"\u001b[0m, line \u001b[1;36m67\u001b[0m, in run_all_system\n",
       "    async for step in \u001b[1;35mgraph.astream\u001b[0m\u001b[1m(\u001b[0mstate\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\"\u001b[0m, line \u001b[1;36m1411\u001b[0m, \n",
       "in astream\n",
       "    async for _ in \u001b[1;35mrunner.atick\u001b[0m\u001b[1m(\u001b[0m\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\"\u001b[0m, line \u001b[1;36m141\u001b[0m, in \n",
       "atick\n",
       "    \u001b[1;35m_panic_or_proceed\u001b[0m\u001b[1m(\u001b[0mall_futures, asyncio.TimeoutError\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\"\u001b[0m, line \u001b[1;36m186\u001b[0m, in \n",
       "_panic_or_proceed\n",
       "    raise exc\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\"\u001b[0m, line \u001b[1;36m79\u001b[0m, in \n",
       "arun_with_retry\n",
       "    await \u001b[1;35mtask.proc.ainvoke\u001b[0m\u001b[1m(\u001b[0mtask.input, task.config\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\"\u001b[0m, line \u001b[1;36m383\u001b[0m, in \n",
       "ainvoke\n",
       "    input = await \u001b[1;35masyncio.create_task\u001b[0m\u001b[1m(\u001b[0mcoro, \u001b[33mcontext\u001b[0m=\u001b[35mcontext\u001b[0m\u001b[1m)\u001b[0m\n",
       "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\"\u001b[0m, line \u001b[1;36m168\u001b[0m, in \n",
       "ainvoke\n",
       "    ret = await \u001b[1;35masyncio.create_task\u001b[0m\u001b[1m(\u001b[0m\n",
       "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\553315941.py\"\u001b[0m, line \u001b[1;36m33\u001b[0m, in profile_analyzer\n",
       "    response = await \u001b[1;35mllm.agenerate\u001b[0m\u001b[1m(\u001b[0mmessages\u001b[1m)\u001b[0m\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Local\\Temp\\ipykernel_51576\\2280079859.py\"\u001b[0m, line \u001b[1;36m67\u001b[0m, in agenerate\n",
       "    completion = await \u001b[1;35mself.client.chat.completions.create\u001b[0m\u001b[1m(\u001b[0m\n",
       "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\"\u001b[0m, line\n",
       "\u001b[1;36m1661\u001b[0m, in create\n",
       "    return await \u001b[1;35mself._post\u001b[0m\u001b[1m(\u001b[0m\n",
       "           ^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"\u001b[0m, line \u001b[1;36m1843\u001b[0m, in post\n",
       "    return await \u001b[1;35mself.request\u001b[0m\u001b[1m(\u001b[0mcast_to, opts, \u001b[33mstream\u001b[0m=\u001b[35mstream\u001b[0m, \u001b[33mstream_cls\u001b[0m=\u001b[35mstream_cls\u001b[0m\u001b[1m)\u001b[0m\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"\u001b[0m, line \u001b[1;36m1537\u001b[0m, in \n",
       "request\n",
       "    return await \u001b[1;35mself._request\u001b[0m\u001b[1m(\u001b[0m\n",
       "           ^^^^^^^^^^^^^^^^^^^^\n",
       "  File \u001b[32m\"C:\\Users\\Ant PC\\AppData\\Roaming\\pypoetry\\venv\\Lib\\site-packages\\openai\\_base_client.py\"\u001b[0m, line \u001b[1;36m1638\u001b[0m, in \n",
       "_request\n",
       "    raise \u001b[1;35mself._make_status_error_from_response\u001b[0m\u001b[1m(\u001b[0merr.response\u001b[1m)\u001b[0m from \u001b[3;35mNone\u001b[0m\n",
       "openai.AuthenticationError: Error code: \u001b[1;36m401\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'status'\u001b[0m: \u001b[1;36m401\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'Unauthorized'\u001b[0m, \u001b[32m'detail'\u001b[0m: \u001b[32m'Authentication \u001b[0m\n",
       "\u001b[32mfailed'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Assuming the NeMoLLaMa and other necessary classes are already imported\n",
    "\n",
    "async def load_json_and_test():\n",
    "    \"\"\"Load JSON files from local system and run the academic assistance system.\"\"\"\n",
    "    print(\"Academic Assistant Test Setup\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Directly specify the file paths for local files\n",
    "    profile_file = 'profile.json'  # Replace with the actual file path\n",
    "    calendar_file = 'calendar.json'  # Replace with the actual file path\n",
    "    task_file = 'task.json'  # Replace with the actual file path\n",
    "    \n",
    "    # Define patterns for matching file types (optional, if needed for validation)\n",
    "    patterns = {\n",
    "        'profile': r'profile.*\\.json$',\n",
    "        'calendar': r'calendar.*\\.json$',\n",
    "        'task': r'task.*\\.json$'\n",
    "    }\n",
    "\n",
    "    # Load JSON contents from local files\n",
    "    try:\n",
    "        # Check if files exist\n",
    "        files = {\n",
    "            'profile': profile_file,\n",
    "            'calendar': calendar_file,\n",
    "            'task': task_file\n",
    "        }\n",
    "\n",
    "        # Validate that files exist\n",
    "        missing = [file_type for file_type, file_path in files.items() if not os.path.exists(file_path)]\n",
    "        if missing:\n",
    "            print(f\"Error: Missing required files: {missing}\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nFiles found:\")\n",
    "        for file_type, file_path in files.items():\n",
    "            print(f\"- {file_type}: {file_path}\")\n",
    "        \n",
    "        # Load JSON contents into dictionaries\n",
    "        json_contents = {}\n",
    "        for file_type, file_path in files.items():\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    json_contents[file_type] = json.load(f)  # Load JSON as a dictionary\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_type} file: {str(e)}\")\n",
    "                    return\n",
    "\n",
    "        print(\"\\nStarting academic assistance workflow...\")\n",
    "\n",
    "        # Initialize NeMoLLaMa with API key (set environment variable if needed)\n",
    "        # os.environ[\"OPENAI_API_KEY\"] = \"your_nemotron_api_key_here\"  # Set your actual API key here\n",
    "        llm = NeMoLLaMa(NEMOTRON_4_340B_INSTRUCT_KEY)  # You can also pass the key directly: NeMoLLaMa(api_key=\"your_nemotron_api_key_here\")\n",
    "        \n",
    "        # Process the files with the system (adjust the run_all_system method as needed)\n",
    "        # Ensure run_all_system method accepts dictionaries, not strings\n",
    "        coordinator_output, output = await run_all_system(\n",
    "            json_contents['profile'],   # Pass as dictionary, not string\n",
    "            json_contents['calendar'],  # Pass as dictionary, not string\n",
    "            json_contents['task']       # Pass as dictionary, not string\n",
    "        )\n",
    "        return coordinator_output, output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return None, None\n",
    "\n",
    "# Run the system\n",
    "coordinator_output, output = await load_json_and_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436735d-e454-4fab-b7a1-8faa12893d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea219f-7e50-44eb-aa40-da6391b3e6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
